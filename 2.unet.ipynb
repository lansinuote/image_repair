{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d54c6dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d34cb1a7bc41c68f984bd73048d328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/104 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655d23552c0f46edb0b87ebcd4a4f072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformer import Transformer2D\n",
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "\n",
    "\n",
    "class Resnet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "\n",
    "        super().__init__()\n",
    "        self.s_in = torch.nn.Sequential(\n",
    "            torch.nn.GroupNorm(32, dim_in, 1e-5, True), torch.nn.SiLU(),\n",
    "            torch.nn.Conv2d(dim_in, dim_out, 3, 1, 1))\n",
    "\n",
    "        self.s_timestep = torch.nn.Sequential(torch.nn.SiLU(),\n",
    "                                              torch.nn.Linear(1280, dim_out))\n",
    "\n",
    "        self.s_out = torch.nn.Sequential(\n",
    "            torch.nn.GroupNorm(32, dim_out, 1e-5, True), torch.nn.SiLU(),\n",
    "            torch.nn.Conv2d(dim_out, dim_out, 3, 1, 1))\n",
    "\n",
    "        self.res = None\n",
    "        if dim_in != dim_out:\n",
    "            self.res = torch.nn.Conv2d(dim_in, dim_out, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x, timestep):\n",
    "        #x -> [1, dim_in, w, h]\n",
    "        #timestep -> [1, 1280]\n",
    "\n",
    "        #[1, dim_in, w, h] -> [1, dim_out, w, h]\n",
    "        res = x\n",
    "        if self.res:\n",
    "            res = self.res(x)\n",
    "\n",
    "        #[1, dim_in, w, h] -> [1, dim_out, w, h]\n",
    "        x = self.s_in(x)\n",
    "\n",
    "        #[1, 1280] -> [1, dim_out, 1, 1]\n",
    "        timestep = self.s_timestep(timestep).unflatten(1, (-1, 1, 1))\n",
    "\n",
    "        #[1, dim_out, w, h] + [1, dim_out, 1, 1] -> [1, dim_out, w, h]\n",
    "        x = x + timestep\n",
    "\n",
    "        #[1, dim_out, w, h]\n",
    "        x = self.s_out(x)\n",
    "\n",
    "        #[1, dim_out, w, h]\n",
    "        return res + x\n",
    "\n",
    "\n",
    "class Upsampler(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv2d(dim, dim, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x, size=None):\n",
    "        #x -> [1, c, w, h]\n",
    "\n",
    "        dtype = x.dtype\n",
    "\n",
    "        #[1, c, w, h] -> [1, c, w*2, h*2]\n",
    "        if size:\n",
    "            x = torch.nn.functional.interpolate(x.to(torch.float32),\n",
    "                                                size=size,\n",
    "                                                mode='nearest').to(dtype)\n",
    "        else:\n",
    "            x = torch.nn.functional.interpolate(x.to(torch.float32),\n",
    "                                                scale_factor=2.0,\n",
    "                                                mode='nearest').to(dtype)\n",
    "\n",
    "        #[1, c, w*2, h*2]\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Mid(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.transformer = Transformer2D(heads=20, dim=1280)\n",
    "        self.resnet1 = Resnet(dim_in=1280, dim_out=1280)\n",
    "        self.resnet2 = Resnet(dim_in=1280, dim_out=1280)\n",
    "\n",
    "    def forward(self, q, kv, timestep):\n",
    "        #q -> [1, 1280, 8, 8]\n",
    "        #kv -> [1, 77, 1024]\n",
    "        #timestep -> [1, 1280]\n",
    "\n",
    "        #[1, 1280, 8, 8]\n",
    "        q = self.resnet1(q, timestep)\n",
    "\n",
    "        #[1, 1280, 8, 8]\n",
    "        q = self.transformer(q, kv=kv)\n",
    "\n",
    "        #[1, 1280, 8, 8]\n",
    "        return self.resnet2(q, timestep)\n",
    "\n",
    "\n",
    "class TransformerDown(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in, dim_out, heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.resnet1 = Resnet(dim_in=dim_in, dim_out=dim_out)\n",
    "        self.resnet2 = Resnet(dim_in=dim_out, dim_out=dim_out)\n",
    "\n",
    "        self.transformer1 = Transformer2D(heads=heads, dim=dim_out)\n",
    "        self.transformer2 = Transformer2D(heads=heads, dim=dim_out)\n",
    "\n",
    "        self.downsampler = torch.nn.Conv2d(dim_out, dim_out, 3, 2, 1)\n",
    "\n",
    "    def forward(self, q, kv, timestep):\n",
    "        #q -> [1, dim_in, w, h]\n",
    "        #kv -> [1, 77, 1024]\n",
    "        #timestep -> [1, 1280]\n",
    "\n",
    "        hidden = []\n",
    "\n",
    "        #[1, dim_in, w, h] -> [1, dim_out, w, h]\n",
    "        q = self.resnet1(q, timestep)\n",
    "        #[1, dim_out, w, h]\n",
    "        q = self.transformer1(q, kv=kv)\n",
    "        hidden.append(q)\n",
    "\n",
    "        #[1, dim_out, w, h]\n",
    "        q = self.resnet2(q, timestep)\n",
    "        #[1, dim_out, w, h]\n",
    "        q = self.transformer2(q, kv=kv)\n",
    "        hidden.append(q)\n",
    "\n",
    "        #[1, dim_out, w/2, h/2]\n",
    "        q = self.downsampler(q)\n",
    "        hidden.append(q)\n",
    "\n",
    "        return q, hidden\n",
    "\n",
    "\n",
    "class Down(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.resnet1 = Resnet(dim_in=1280, dim_out=1280)\n",
    "        self.resnet2 = Resnet(dim_in=1280, dim_out=1280)\n",
    "\n",
    "    def forward(self, q, timestep, **kwargs):\n",
    "        #q -> [1, 1280, 8, 8]\n",
    "        #timestep -> [1, 1280]\n",
    "\n",
    "        hidden = []\n",
    "\n",
    "        #[1, 1280, 8, 8]\n",
    "        q = self.resnet1(q, timestep)\n",
    "        hidden.append(q)\n",
    "\n",
    "        #[1, 1280, 8, 8]\n",
    "        q = self.resnet2(q, timestep)\n",
    "        hidden.append(q)\n",
    "\n",
    "        return q, hidden\n",
    "\n",
    "\n",
    "class Up(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.resnet = torch.nn.ModuleList([\n",
    "            Resnet(dim_in=2560, dim_out=1280),\n",
    "            Resnet(dim_in=2560, dim_out=1280),\n",
    "            Resnet(dim_in=2560, dim_out=1280)\n",
    "        ])\n",
    "\n",
    "        self.upsampler = Upsampler(1280)\n",
    "\n",
    "    def forward(self, q, hidden, timestep, size, **kwargs):\n",
    "        #q -> [1, 1280, 8, 8]\n",
    "        #hidden ->  [[1, 1280, 8, 8], [1, 1280, 8, 8], [1, 1280, 8, 8]]\n",
    "\n",
    "        for i in self.resnet:\n",
    "            #[1, 1280+1280, 8, 8] -> [1, 2560, 8, 8]\n",
    "            q = torch.cat([q, hidden.pop(-1)], dim=1)\n",
    "            q = i(q, timestep)\n",
    "\n",
    "        #[1, 2560, 8, 8] -> [1, 2560, 16, 16]\n",
    "        return self.upsampler(q, size)\n",
    "\n",
    "\n",
    "class TransformerUp(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in, dim_out, dim_hidden, heads, add_upsample):\n",
    "        super().__init__()\n",
    "\n",
    "        self.transformer = torch.nn.ModuleList([\n",
    "            Transformer2D(heads=heads, dim=dim_out),\n",
    "            Transformer2D(heads=heads, dim=dim_out),\n",
    "            Transformer2D(heads=heads, dim=dim_out)\n",
    "        ])\n",
    "\n",
    "        self.resnet = torch.nn.ModuleList([\n",
    "            Resnet(dim_in=dim_hidden + dim_out, dim_out=dim_out),\n",
    "            Resnet(dim_in=dim_out + dim_out, dim_out=dim_out),\n",
    "            Resnet(dim_in=dim_out + dim_in, dim_out=dim_out)\n",
    "        ])\n",
    "\n",
    "        self.upsampler = None\n",
    "        if add_upsample:\n",
    "            self.upsampler = Upsampler(dim_out)\n",
    "\n",
    "    def forward(self, q, hidden, timestep, kv, size=None):\n",
    "        #q -> [1, dim_hidden, w, h]\n",
    "        #hidden -> [[1, dim_in, w, h], [1, dim_out, w, h], [1, dim_out, w, h]]\n",
    "\n",
    "        for i in range(3):\n",
    "            #[1, dim_hidden+..., w, h]\n",
    "            h = hidden.pop(-1)\n",
    "            q = torch.cat([q, h], dim=1)\n",
    "            #[1, dim_hidden+..., w, h] -> [1, dim_out, w, h]\n",
    "            q = self.resnet[i](q, timestep)\n",
    "            #[1, dim_out, w, h]\n",
    "            q = self.transformer[i](q, kv=kv)\n",
    "\n",
    "        if self.upsampler:\n",
    "            #[1, dim_out, w, h] -> [1, dim_out, w*2, h*2]\n",
    "            q = self.upsampler(q, size)\n",
    "\n",
    "        return q\n",
    "\n",
    "\n",
    "class TimestepEmbedding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.s = torch.nn.Sequential(torch.nn.Linear(320, 1280),\n",
    "                                     torch.nn.SiLU(),\n",
    "                                     torch.nn.Linear(1280, 1280))\n",
    "\n",
    "        import math\n",
    "        embedding = torch.arange(160, dtype=torch.float32)\n",
    "        embedding = (embedding * -math.log(10000) / 160).exp()\n",
    "        self.register_buffer('embedding', embedding)\n",
    "\n",
    "    def forward(self, timestep, dtype):\n",
    "        #[1, 160]\n",
    "        timestep = (timestep * self.embedding).reshape(1, -1)\n",
    "\n",
    "        #[1, 160] -> [1, 320]\n",
    "        timestep = torch.cat([timestep.cos(), timestep.sin()],\n",
    "                             dim=1).to(dtype=dtype)\n",
    "\n",
    "        #[1, 320] -> [1, 1280]\n",
    "        return self.s(timestep)\n",
    "\n",
    "\n",
    "class UNet(PreTrainedModel):\n",
    "    config_class = PretrainedConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.timestep_embedding = TimestepEmbedding()\n",
    "\n",
    "        self.down = torch.nn.ModuleList([\n",
    "            TransformerDown(dim_in=320, dim_out=320, heads=5),\n",
    "            TransformerDown(dim_in=320, dim_out=640, heads=10),\n",
    "            TransformerDown(dim_in=640, dim_out=1280, heads=20),\n",
    "            Down()\n",
    "        ])\n",
    "\n",
    "        self.mid = Mid()\n",
    "\n",
    "        self.up = torch.nn.ModuleList([\n",
    "            Up(),\n",
    "            TransformerUp(dim_in=640,\n",
    "                          dim_out=1280,\n",
    "                          dim_hidden=1280,\n",
    "                          heads=20,\n",
    "                          add_upsample=True),\n",
    "            TransformerUp(dim_in=320,\n",
    "                          dim_out=640,\n",
    "                          dim_hidden=1280,\n",
    "                          heads=10,\n",
    "                          add_upsample=True),\n",
    "            TransformerUp(dim_in=320,\n",
    "                          dim_out=320,\n",
    "                          dim_hidden=640,\n",
    "                          heads=5,\n",
    "                          add_upsample=False)\n",
    "        ])\n",
    "\n",
    "        self.s_in = torch.nn.Conv2d(4, 320, kernel_size=3, padding=1)\n",
    "\n",
    "        self.s_out = torch.nn.Sequential(\n",
    "            torch.nn.GroupNorm(num_channels=320, num_groups=32, eps=1e-5),\n",
    "            torch.nn.SiLU(), torch.nn.Conv2d(320, 4, kernel_size=3, padding=1))\n",
    "\n",
    "    def forward(self,\n",
    "                q,\n",
    "                kv,\n",
    "                timestep,\n",
    "                controlnet_down=None,\n",
    "                controlnet_mid=None):\n",
    "        #q -> [1, 4, 64, 64]\n",
    "        #kv -> [1, 77, 1024]\n",
    "        #timestep -> [1]\n",
    "\n",
    "        #[1, 1280]\n",
    "        timestep = self.timestep_embedding(timestep, q.dtype)\n",
    "\n",
    "        #[1, 4, 64, 64] -> [1, 320, 64, 64]\n",
    "        q = self.s_in(q)\n",
    "\n",
    "        out = [q]\n",
    "\n",
    "        for i in range(4):\n",
    "            #[1, 320, 64, 64] -> [1, 320, 32, 32]\n",
    "            #[1, 320, 32, 32] -> [1, 640, 16, 16]\n",
    "            #[1, 640, 16, 16] -> [1, 1280, 8, 8]\n",
    "            #[1, 1280, 8, 8] -> [1, 1280, 8, 8]\n",
    "            q, hidden = self.down[i](q=q, kv=kv, timestep=timestep)\n",
    "            out.extend(list(hidden))\n",
    "\n",
    "        if controlnet_down is not None:\n",
    "            for i in range(len(out)):\n",
    "                out[i] = out[i] + controlnet_down[i]\n",
    "\n",
    "        #[1, 1280, 8, 8]\n",
    "        q = self.mid(q=q, kv=kv, timestep=timestep)\n",
    "\n",
    "        if controlnet_mid is not None:\n",
    "            q = q + controlnet_mid\n",
    "\n",
    "        for i in range(4):\n",
    "            hidden = [out.pop(-1) for _ in range(3)]\n",
    "            hidden = list(reversed(hidden))\n",
    "\n",
    "            size = None\n",
    "            if out:\n",
    "                size = out[-1].shape[2:]\n",
    "\n",
    "            #[1, 1280, 8, 8] -> [1, 1280, 16, 16]\n",
    "            #[1, 1280, 16, 16] -> [1, 1280, 32, 32]\n",
    "            #[1, 1280, 32, 32] -> [1, 640, 64, 64]\n",
    "            #[1, 640, 64, 64] -> [1, 320, 64, 64]\n",
    "            q = self.up[i](q=q,\n",
    "                           hidden=hidden,\n",
    "                           kv=kv,\n",
    "                           timestep=timestep,\n",
    "                           size=size)\n",
    "\n",
    "        #[1, 320, 64, 64] -> [1, 4, 64, 64]\n",
    "        return self.s_out(q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cuda117]",
   "language": "python",
   "name": "conda-env-cuda117-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
