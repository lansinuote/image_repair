{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65915b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input': Compose(\n",
       "      Resize(size=1023, interpolation=bilinear, max_size=1024, antialias=None)\n",
       "  ),\n",
       "  'to_tensor': Compose(\n",
       "      ToTensor()\n",
       "      Normalize(mean=[0.5], std=[0.5])\n",
       "  ),\n",
       "  'to_tensor_encoder': Compose(\n",
       "      ToTensor()\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "  )},\n",
       " DDPMScheduler {\n",
       "   \"_class_name\": \"DDPMScheduler\",\n",
       "   \"_diffusers_version\": \"0.30.1\",\n",
       "   \"beta_end\": 0.012,\n",
       "   \"beta_schedule\": \"scaled_linear\",\n",
       "   \"beta_start\": 0.00085,\n",
       "   \"clip_sample\": false,\n",
       "   \"clip_sample_range\": 1.0,\n",
       "   \"dynamic_thresholding_ratio\": 0.995,\n",
       "   \"num_train_timesteps\": 1000,\n",
       "   \"prediction_type\": \"epsilon\",\n",
       "   \"rescale_betas_zero_snr\": false,\n",
       "   \"sample_max_value\": 1.0,\n",
       "   \"steps_offset\": 1,\n",
       "   \"thresholding\": false,\n",
       "   \"timestep_spacing\": \"leading\",\n",
       "   \"trained_betas\": null,\n",
       "   \"variance_type\": \"fixed_small\"\n",
       " })"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import PIL.Image\n",
    "\n",
    "device = 'cuda'\n",
    "dtype = torch.float16\n",
    "\n",
    "compose = {\n",
    "    'input':\n",
    "    torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(size=1023, max_size=1024),\n",
    "    ]),\n",
    "    'to_tensor':\n",
    "    torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.5], [0.5])\n",
    "    ]),\n",
    "    'to_tensor_encoder':\n",
    "    torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                         std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "}\n",
    "\n",
    "from diffusers import DDPMScheduler\n",
    "\n",
    "scheduler_noise = DDPMScheduler(beta_end=0.012,\n",
    "                                beta_schedule='scaled_linear',\n",
    "                                beta_start=0.00085,\n",
    "                                clip_sample=False,\n",
    "                                steps_offset=1)\n",
    "scheduler_noise.set_timesteps(50)\n",
    "\n",
    "compose, scheduler_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 1.vae.ipynb\n",
    "vae = VAE.from_pretrained('lansinuote/image_repair.vae')\n",
    "\n",
    "%run 2.unet.ipynb\n",
    "unet = UNet.from_pretrained('lansinuote/image_repair.unet')\n",
    "\n",
    "%run 3.encoder.ipynb\n",
    "encoder = Encoder.from_pretrained('lansinuote/image_repair.encoder')\n",
    "\n",
    "%run 4.controlnet.ipynb\n",
    "controlnet = ControlNet.from_pretrained('lansinuote/image_repair.controlnet',\n",
    "                                        unet=unet)\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "#controlnet.load_state_dict(torch.load('model/controlnet_1730709235'))\n",
    "\n",
    "vae.requires_grad_(False).to(device, dtype)\n",
    "unet.requires_grad_(False).to(device, dtype)\n",
    "encoder.requires_grad_(False).to(device, dtype)\n",
    "controlnet.eval()\n",
    "\n",
    "accelerator = Accelerator(mixed_precision='fp16')\n",
    "\n",
    "controlnet = accelerator.prepare(controlnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32305db",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(image_small, image_original):\n",
    "    q, _ = vae.encode(image_small)\n",
    "    q = torch.randn_like(q)\n",
    "\n",
    "    kv = encoder(image_original).to(device, dtype)\n",
    "\n",
    "    for timestep in scheduler_noise.timesteps:\n",
    "        controlnet_down, controlnet_mid = controlnet(\n",
    "            q=q, kv=kv, timestep=timestep, controlnet_cond=image_small)\n",
    "\n",
    "        controlnet_mid = controlnet_mid.to(device, dtype)\n",
    "        controlnet_down = [i.to(device, dtype) for i in controlnet_down]\n",
    "\n",
    "        pred_noise = unet(q=q,\n",
    "                          kv=kv,\n",
    "                          timestep=timestep,\n",
    "                          controlnet_down=controlnet_down,\n",
    "                          controlnet_mid=controlnet_mid)\n",
    "\n",
    "        q = scheduler_noise.step(pred_noise, timestep, q, return_dict=False)[0]\n",
    "\n",
    "    return vae.decode(q / 0.18215)\n",
    "\n",
    "\n",
    "predict(\n",
    "    torch.randn(1, 3, 100, 100).to(device, dtype),\n",
    "    torch.randn(1, 3, 100, 100).to(device, dtype)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2495ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image):\n",
    "    image = compose['input'](image)\n",
    "    image_small = compose['to_tensor'](image).unsqueeze(0).to(device, dtype)\n",
    "    image_original = compose['to_tensor_encoder'](image).unsqueeze(0).to(\n",
    "        device, dtype)\n",
    "\n",
    "    image_predict = predict(image_small, image_original)\n",
    "\n",
    "    image_predict = image_predict.detach().cpu().float()\n",
    "    image_predict = image_predict[0].permute(1, 2, 0).numpy()\n",
    "    image_predict = image_predict * 0.5 + 0.5\n",
    "    image_predict = (image_predict * 255).clip(0, 255).astype('uint8')\n",
    "\n",
    "    return PIL.Image.fromarray(image_predict)\n",
    "\n",
    "\n",
    "predict_image(PIL.Image.open('dataset/image_test/1700.jpg').convert('RGB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d321eee4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "root = 'dataset/image_test'\n",
    "for filename in os.listdir(root):\n",
    "    try:\n",
    "        image = PIL.Image.open(os.path.join(root, filename)).convert('RGB')\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    print(filename)\n",
    "\n",
    "    image = image.resize([i // 4 for i in image.size])\n",
    "\n",
    "    path = os.path.join(root, 'original', filename)\n",
    "    image.save(path)\n",
    "    image = PIL.Image.open(path)\n",
    "\n",
    "    image = image.resize([i * 4 for i in image.size])\n",
    "\n",
    "    try:\n",
    "        image = predict_image(image)\n",
    "    except:\n",
    "        continue\n",
    "    path = os.path.join(root, 'predict', filename)\n",
    "    image.save(path)\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cuda117]",
   "language": "python",
   "name": "conda-env-cuda117-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
